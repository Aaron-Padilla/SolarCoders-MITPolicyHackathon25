# Install dependencies
!pip install requests pandas matplotlib python-dotenv


# Imports
import os
import getpass
from datetime import datetime
import requests
import pandas as pd
import matplotlib.pyplot as plt

# Make plots a bit nicer
plt.style.use("default")

# API KEY + HEADERS
API_KEY = "dd84e19792104cfb817604354b3456b0"

headers = {
    "x-api-key": API_KEY
}

BASE_URL = "https://api.gridstatus.io/v1"

# test request
resp = requests.get(f"{BASE_URL}/datasets", headers=headers)
print(resp.status_code)
data=resp.json()
data.keys()



pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
df = pd.DataFrame(data["data"])
df.head()


df_pjm = df[df["source"] == "pjm"]
df_pjm[["id", "name", "description"]]



df_pjm_selected = df_pjm[["id", "name", "description"]]
df_pjm_selected.head()
df_pjm_selected.to_csv("pjm_datasets_list.csv", index=False)






df_lmp.columns


df_lmp["interval_start_utc"] = pd.to_datetime(df_lmp["interval_start_utc"])

df_lmp["hour"] = df_lmp["interval_start_utc"].dt.hour

avg_by_hour = df_lmp.groupby("hour")["lmp"].mean()
avg_by_hour



dataset_id = "pjm_lmp_real_time_hourly"
location = "ATSI"  

resp = requests.get(
    f"{BASE_URL}/datasets/{dataset_id}/query/location/{location}",
    headers=headers,
    params={
        "start_time": "2024-01-10T00:00Z",
        "end_time":   "2024-01-11T00:00Z",
        "limit": 5000
    }
)

df_lmp = pd.DataFrame(resp.json()["data"])
df_lmp.head()



df_lmp["interval_start_utc"] = pd.to_datetime(df_lmp["interval_start_utc"])




df_lmp = df_lmp.sort_values("interval_start_utc")



plt.figure(figsize=(12,4))
plt.plot(df_lmp["interval_start_utc"], df_lmp["lmp"])
plt.title("PJM Real-Time LMP (Hourly) â€“  ATSI")
plt.xlabel("Time")
plt.ylabel("Price ($/MWh)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()



# HELPER FUNCTION: GET PJM LMP DATA
# -------------------------------------------------------
def get_pjm_lmp(start_time, end_time, location="ATSI"):
    """
    Retrieve PJM Real-Time Hourly LMP for a given time range and location.
    - start_time, end_time: ISO timestamps
    - location: PJM zone (ATSI for Bowling Green)
    Returns:
    - Clean pandas DataFrame: timestamps + price components
    """
    dataset_id = "pjm_lmp_real_time_hourly"
    
    # API request
    resp = requests.get(
        f"{BASE_URL}/datasets/{dataset_id}/query/location/{location}",
        headers=headers,
        params={
            "start_time": start_time,
            "end_time": end_time,
            "limit": 50000
        }
    )
    
    # Convert JSON to DataFrame
    df = pd.DataFrame(resp.json()["data"])
    
    # Convert timestamps
    df["interval_start_utc"] = pd.to_datetime(df["interval_start_utc"])
    
    # Sort by time
    df = df.sort_values("interval_start_utc")
    
    return df

### Understanding Timestamps (ISO 8601)

'''GridStatus API requires timestamps in ISO 8601 UTC format:

    YYYY-MM-DDTHH:MMZ

- `T` separates date and time  
- `Z` means UTC timezone  
- `00:00` means midnight  
- Using `T00:00Z` gives clean day boundaries

Example:
`2024-01-01T00:00Z` â†’ Jan 1st at 12:00 AM UTC'''





# -------------------------------------------------------
# WINTER DAY: Jan 10, 2024
# -------------------------------------------------------
winter_start = "2024-01-10T00:00Z"
winter_end   = "2024-01-11T00:00Z"

df_winter = get_pjm_lmp(winter_start, winter_end, "ATSI")

# Plot winter LMP
plt.figure(figsize=(12,4))
plt.plot(df_winter["interval_start_utc"], df_winter["lmp"])
plt.title("Winter Day LMP â€“ ATSI Zone")
plt.xlabel("Hour")
plt.ylabel("LMP ($/MWh)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()






# -------------------------------------------------------
# SUMMER DAY: July 15, 2024
# -------------------------------------------------------
summer_start = "2024-07-15T00:00Z"
summer_end   = "2024-07-16T00:00Z"

df_summer = get_pjm_lmp(summer_start, summer_end, "ATSI")

# Plot summer LMP
plt.figure(figsize=(12,4))
plt.plot(df_summer["interval_start_utc"], df_summer["lmp"], color="orange")
plt.title("Summer Day LMP â€“ ATSI Zone")
plt.xlabel("Hour")
plt.ylabel("LMP ($/MWh)")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()






# -------------------------------------------------------
# ONE WEEK: Jan 1â€“7, 2024
# -------------------------------------------------------
week_start = "2024-01-01T00:00Z"
week_end   = "2024-01-08T00:00Z"

df_week = get_pjm_lmp(week_start, week_end, "ATSI")

# Add hour column for hourly averages
df_week["hour"] = df_week["interval_start_utc"].dt.hour

avg_by_hour = df_week.groupby("hour")["lmp"].mean()
avg_by_hour



plt.figure(figsize=(10,4))
avg_by_hour.plot(marker="o")
plt.title("Average Hourly LMP (One Week) â€“ ATSI Zone")
plt.xlabel("Hour of Day")
plt.ylabel("LMP ($/MWh)")
plt.grid(True)
plt.show()



solar_hours = avg_by_hour.loc[10:14].mean()  # solar noon
peak_hours  = avg_by_hour.loc[17:20].mean()  # evening peak
min_price = df_week["lmp"].min()
max_price = df_week["lmp"].max()
overall_avg = df_week["lmp"].mean()

solar_hours, peak_hours, min_price, max_price, overall_avg






df_lmp = df_pjm[df_pjm["id"].str.contains("lmp", case=False)]
df_lmp.to_csv("pjm_lmp_datasets.csv", index=False)



df_load = df_pjm[df_pjm["id"].str.contains("load", case=False)]
df_load.to_csv("pjm_load_datasets.csv", index=False)



df_solar = df_pjm[df_pjm["id"].str.contains("solar", case=False)]
df_solar.to_csv("pjm_solar_datasets.csv", index=False)









import pandas as pd
import requests
from datetime import datetime
from tqdm.notebook import tqdm  # tqdm progress bar for Jupyter


# -----------------------------
# FUNCTION: GET ONE MONTH OF DATA
# -----------------------------

dataset_id = "pjm_lmp_real_time_hourly"   # LMP dataset
location = "ATSI"                          # ATSI zone
def fetch_month(year, month):
    start = f"{year}-{month:02d}-01T00:00Z"
    
    if month == 12:
        end = f"{year+1}-01-01T00:00Z"
    else:
        end = f"{year}-{month+1:02d}-01T00:00Z"

    resp = requests.get(
        f"{BASE_URL}/datasets/{dataset_id}/query/location/{location}",
        headers=headers,
        params={"start_time": start, "end_time": end, "limit": 50000}
    )
    
    data = resp.json().get("data", [])
    if not data:
        return None
    
    df = pd.DataFrame(data)
    df["interval_start_utc"] = pd.to_datetime(df["interval_start_utc"])
    return df.sort_values("interval_start_utc")


# -----------------------------
# DOWNLOAD MONTH-BY-MONTH WITH TQDM
# -----------------------------
start_year = 2015
end_year = 2026

years = list(range(start_year, end_year + 1))
months = range(1, 13)

all_data = []

print("ðŸš€ Starting ATSI LMP monthly download...\n")

# tqdm nested loops for months
for year in tqdm(years, desc="Years"):
    for month in tqdm(months, desc=f"Months in {year}", leave=False):
        
        df_month = fetch_month(year, month)
        
        if df_month is not None:
            all_data.append(df_month)


# -----------------------------
# MERGE AND SAVE
# -----------------------------
if all_data:
    df_all = pd.concat(all_data, ignore_index=True)
    df_all.to_csv("ATSI_LMP_2015_2026.csv", index=False)
    print("\n DONE â€” Saved: ATSI_LMP_2015_2026.csv")
    print(f"Total rows: {len(df_all)}")
else:
    print("\n No data downloaded. Check date range or dataset availability.")






import pandas as pd
import requests
from tqdm.notebook import tqdm
from datetime import datetime

# -----------------------------
# SETTINGS
# -----------------------------

dataset_id = "pjm_load_metered_hourly"  # load dataset
location = "ATSI"                       # filter by area column

# -----------------------------
# FUNCTION: GET ONE MONTH OF LOAD DATA
# -----------------------------
def fetch_month(year, month):
    start = f"{year}-{month:02d}-01T00:00Z"
    if month == 12:
        end = f"{year+1}-01-01T00:00Z"
    else:
        end = f"{year}-{month+1:02d}-01T00:00Z"

    resp = requests.get(
        f"{BASE_URL}/datasets/{dataset_id}/query",
        headers=headers,
        params={"start_time": start, "end_time": end, "limit": 50000}
    )

    data = resp.json().get("data", [])
    if not data:
        return None

    df = pd.DataFrame(data)

    # load dataset uses time_utc instead of interval_start_utc
    df["time_utc"] = pd.to_datetime(df["time_utc"])

    # filter by ATSI area
    df = df[df["area"] == location]

    if df.empty:
        return None

    return df.sort_values("time_utc")

# -----------------------------
# MONTHLY DOWNLOAD WITH TQDM
# -----------------------------
start_year = 2015
end_year = 2026

years = list(range(start_year, end_year + 1))
months = range(1, 13)

all_data = []

print("Starting ATSI Load monthly download...\n")

for year in tqdm(years, desc="Years"):
    for month in tqdm(months, desc=f"Months in {year}", leave=False):

        df_month = fetch_month(year, month)
        if df_month is not None:
            all_data.append(df_month)

# -----------------------------
# MERGE & SAVE
# -----------------------------
if all_data:
    df_all = pd.concat(all_data, ignore_index=True)
    df_all.to_csv("ATSI_Load_2015_2025.csv", index=False)
    print("\n DONE â€” Saved ATSI_Load_2015_2025.csv")
    print(f"Total rows: {len(df_all)}")
else:
    print("\n No data downloaded â€” check dates or dataset availability.")



resp = requests.get(
    f"{BASE_URL}/datasets/pjm_load_metered_hourly/query",
    headers=headers,
    params={
        "start_time": "2024-01-01T00:00Z",
        "end_time":   "2024-01-02T00:00Z",
        "limit": 5000
    }
)

df_test = pd.DataFrame(resp.json()["data"])
df_test.head()
df_test.columns




